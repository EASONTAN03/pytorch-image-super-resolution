# PyTorch Image Super-Resolution

PyTorch reimplementation of SRCNN and SRGAN for single-image super-resolution on the DIV2K dataset. Features a modular codebase with shared components for fair comparison between CNN- and GAN-based methods. Includes training, evaluation, and reproducibility support to validate results against the original papers.

## ğŸš€ Features

- **Multiple Models**: SRCNN (CNN-based) and SRGAN (GAN-based) implementations
- **Modular Design**: Shared components for fair model comparison
- **TensorBoard Integration**: Real-time training monitoring and visualization
- **CUDA Support**: GPU acceleration for faster training and inference
- **Comprehensive Evaluation**: PSNR and SSIM metrics for quality assessment
- **Flexible Dataset**: Support for DIV2K training and Set5 validation
- **Configuration Management**: YAML-based configuration for easy experimentation

## ğŸ“ Project Structure

```
pytorch-image-super-resolution/
â”œâ”€â”€ README.md                    # Project documentation
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ config.yaml                  # Training configuration
â”œâ”€â”€ make_dataset.py             # Dataset preprocessing script
â”œâ”€â”€ .cursorignore               # Cursor IDE ignore file
â”‚
â”œâ”€â”€ src/                        # Source code directory
â”‚   â”œâ”€â”€ train.py                # Main training script
â”‚   â”œâ”€â”€ evaluate.py             # Model evaluation script
â”‚   â”œâ”€â”€ dataset.py              # Dataset loading and preprocessing
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # Model architectures
â”‚   â”‚   â”œâ”€â”€ SRCNN.py           # SRCNN implementation
â”‚   â”‚   â””â”€â”€ SRGAN.py           # SRGAN implementation
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # Utility functions
â”‚       â”œâ”€â”€ dataset.py          # Dataset utilities
â”‚       â”œâ”€â”€ imgproc.py          # Image processing functions
â”‚       â””â”€â”€ model.py            # Model utilities
â”‚
â”œâ”€â”€ dataset/                    # Dataset directory
â”‚   â”œâ”€â”€ raw/                    # Raw dataset files
â”‚   â”‚   â”œâ”€â”€ DIV2K/             # DIV2K dataset
â”‚   â”‚   â”‚   â”œâ”€â”€ HR/            # High-resolution images
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ train/     # Training images
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ valid/     # Validation images
â”‚   â”‚   â”‚   â””â”€â”€ LR/            # Low-resolution images (generated)
â”‚   â”‚   â””â”€â”€ Set5/              # Set5 test dataset
â”‚   â”‚
â”‚   â””â”€â”€ prepared/               # Processed dataset
â”‚       â”œâ”€â”€ DIV2K/             # Processed DIV2K
â”‚       â”‚   â”œâ”€â”€ hr/            # High-resolution patches (96x96)
â”‚       â”‚   â””â”€â”€ lr/            # Low-resolution patches (24x24)
â”‚       â””â”€â”€ Set5/              # Processed Set5
â”‚           â””â”€â”€ valid/         # Validation set
â”‚
â”œâ”€â”€ backup/                     # Backup files
â”‚   â”œâ”€â”€ make_dataset.py        # Backup dataset script
â”‚   â””â”€â”€ make_dataset copy.py   # Dataset script copy
â”‚
â”œâ”€â”€ documents/                  # Research papers and documentation
â”‚   â”œâ”€â”€ 1501.00092v3.pdf       # SRCNN paper
â”‚   â”œâ”€â”€ 1609.04802v5.pdf       # SRGAN paper
â”‚   â”œâ”€â”€ 2006.13846v2.pdf       # Additional research
â”‚   â”œâ”€â”€ Notes and Plan.docx    # Project notes
â”‚   â””â”€â”€ ...                    # Other research papers
â”‚
â”œâ”€â”€ samples/                    # Generated during training
â”‚   â”œâ”€â”€ logs/                  # TensorBoard logs
â”‚   â””â”€â”€ {exp_name}/            # Experiment-specific outputs
â”‚
â””â”€â”€ results/                    # Training results
    â””â”€â”€ {exp_name}/            # Model checkpoints and outputs
        â”œâ”€â”€ best.pth.tar       # Best model checkpoint
        â””â”€â”€ last.pth.tar       # Latest model checkpoint
```

## ğŸ› ï¸ Installation

### 1. Environment Setup

```bash
# Create conda environment
conda create -n pytorch-image-super-resolution python==3.11
conda activate pytorch-image-super-resolution

# Install dependencies
pip install -r requirements.txt

# Install PyTorch with CUDA support
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
```

### 2. Required Dependencies

```
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0
tensorboard>=2.13.0
opencv-python>=4.7.0
numpy>=1.24.0
pyyaml>=6.0
pillow>=9.5.0
```

## ğŸ“Š Dataset Setup

### Dataset Structure

The project expects the following dataset structure:

```
dataset/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ DIV2K/
â”‚   â”‚   â””â”€â”€ HR/
â”‚   â”‚       â”œâ”€â”€ train/          # DIV2K training images
â”‚   â”‚       â””â”€â”€ valid/          # DIV2K validation images
â”‚   â””â”€â”€ Set5/                   # Set5 test images (ground truth)
â”‚
â””â”€â”€ prepared/
    â”œâ”€â”€ DIV2K/
    â”‚   â”œâ”€â”€ hr/                 # 96x96 HR patches
    â”‚   â””â”€â”€ lr/                 # 24x24 LR patches (X4 downscale)
    â””â”€â”€ Set5/
        â””â”€â”€ valid/              # Processed Set5 validation
```

### Dataset Preprocessing

Generate training patches from raw images:

```bash
# Linux/macOS
python make_dataset.py \
  --train_dir dataset/raw/DIV2K/HR/train \
  --valid_dir dataset/raw/DIV2K/HR/valid \
  --output_dir dataset/prepared/DIV2K \
  --crop_size 96 \
  --stride 48 \
  --upscale_factor 4 \
  --interpolation cubic

# Windows PowerShell
python make_dataset.py `
  --train_dir dataset/raw/DIV2K/HR/train `
  --valid_dir dataset/raw/DIV2K/HR/valid `
  --output_dir dataset/prepared/DIV2K `
  --crop_size 96 `
  --stride 48 `
  --upscale_factor 4 `
  --interpolation cubic
```

## âš™ï¸ Configuration

The `config.yaml` file contains all training parameters:

```yaml
# Model selection: "SRCNN" or "SRGAN"
model: "SRCNN"

# Dataset configuration
dataset:
  train_image_dir: "dataset/prepared/DIV2K/hr"
  test_lr_image_dir: "dataset/prepared/Set5/valid"
  test_hr_image_dir: "dataset/raw/Set5"
  image_size: 96
  upscale_factor: 4
  batch_size: 16
  num_workers: 4

# Training parameters
train:
  epochs: 1000
  learning_rate: 1e-4
  momentum: 0.9
  weight_decay: 1e-4
  print_frequency: 100

# Device configuration
device: "cuda"  # or "cpu"
```

## ğŸš€ Usage

### Training

Train SRCNN model:
```bash
python src/train.py
```

The training script will:
- Load configuration from `config.yaml`
- Initialize the selected model (SRCNN or SRGAN)
- Set up data loaders for training and validation
- Start training with TensorBoard logging
- Save model checkpoints in `results/` directory

### Monitoring Training

View training progress with TensorBoard:
```bash
tensorboard --logdir samples/logs
```

### Evaluation

Evaluate trained model:
```bash
python src/evaluate.py --model_path results/best.pth.tar
```

## ğŸ—ï¸ Model Architectures

### SRCNN (Super-Resolution Convolutional Neural Network)

- **Architecture**: 3-layer CNN
- **Input**: 24x24 LR Y-channel images
- **Output**: 96x96 SR Y-channel images
- **Upscaling**: 4x super-resolution
- **Loss**: Mean Squared Error (MSE)

### SRGAN (Super-Resolution Generative Adversarial Network)

- **Generator**: ResNet-based architecture with 16 residual blocks
- **Discriminator**: VGG-inspired discriminator network
- **Upscaling**: 4x super-resolution using sub-pixel convolution
- **Loss**: Adversarial loss + Content loss (VGG features) + MSE loss

## ğŸ“ˆ Key Components

### Dataset Loading (`src/dataset.py`)
- `TrainValidImageDataset`: Handles training/validation data loading
- `TestImageDataset`: Handles test data loading
- `CUDAPrefetcher`: Accelerates data loading using CUDA streams

### Image Processing (`src/utils/imgproc.py`)
- Color space conversion (BGR â†” YCbCr)
- Image resizing and cropping
- Tensor conversion utilities

### Training Loop (`src/train.py`)
- Mixed precision training with AMP
- TensorBoard logging
- Model checkpointing
- PSNR/SSIM evaluation

## ğŸ”§ Customization

### Adding New Models

1. Create model file in `src/models/`
2. Implement PyTorch `nn.Module` class
3. Add model import and initialization in `src/train.py`
4. Update `config.yaml` with model-specific parameters

### Modifying Training Parameters

Edit `config.yaml` to adjust:
- Learning rate and optimization parameters
- Batch size and data loading settings
- Model architecture parameters
- Training duration and checkpointing

## ğŸ“Š Expected Results

### SRCNN
- **PSNR**: ~30.48 dB on Set5
- **SSIM**: ~0.8626 on Set5
- **Training Time**: ~2-3 hours on RTX 3080

### SRGAN
- **PSNR**: ~29.40 dB on Set5
- **SSIM**: ~0.8472 on Set5
- **Training Time**: ~8-10 hours on RTX 3080

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“š References

- [SRCNN Paper](https://arxiv.org/abs/1501.00092): "Image Super-Resolution Using Deep Convolutional Networks"
- [SRGAN Paper](https://arxiv.org/abs/1609.04802): "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"
- [DIV2K Dataset](https://data.vision.ee.ethz.ch/cvl/DIV2K/): High-quality images for super-resolution
- [Set5 Dataset](http://people.rennes.inria.fr/Aline.Roumy/results/SR_BMVC12.html): Standard super-resolution benchmark

## ğŸ› Troubleshooting

### Common Issues

1. **CUDA Out of Memory**: Reduce batch size in `config.yaml`
2. **Dataset Not Found**: Ensure dataset paths are correct in configuration
3. **Import Errors**: Check that all dependencies are installed
4. **Training Slow**: Verify CUDA installation and GPU availability

### Performance Tips

- Use mixed precision training (enabled by default)
- Increase `num_workers` for faster data loading
- Use SSD storage for dataset to reduce I/O bottleneck
- Monitor GPU utilization with `nvidia-smi`
